# Langchain

LangChain is a framework for building applications with large language models (LLMs) using modular components.

## Components

### Models
* [Large Language Models LLMs](/LangChain/COMPONENTS.md#2-llm)
* [Chat Models](/LangChain/COMPONENTS.md#1-chat-models)
* [Text Embedding Models](/LangChain/COMPONENTS.md#11-embedding-models)

### Prompts
* [Prompts Templates](/LangChain/COMPONENTS.md#4-prompt-templates)
* [Few-Shot Prompting](/LangChain/TECHNIQUES.md#4-few-shot-prompting)
* [Output Parser](/LangChain/COMPONENTS.md#6-output-parser)
* [Example Selectors](/LangChain/COMPONENTS.md#5-example-selectors)

### Indexes
* [Document Loaders](/LangChain/COMPONENTS.md#9-document-loaders)
* [Text Splitters](/LangChain/TECHNIQUES.md#6-text-splitting)
* [Vector Stores](/LangChain/COMPONENTS.md#12-vector-stores)
* [Retrievers](/LangChain/TECHNIQUES.md#5-retrieval-strategies-overview)

### [Chains](/LangChain/README.md#2-chains)
* Prompt + LLM + Output Parsing
* Can be used as building  blocks for longer chains
* More application specific chains

## 1. Memory

***ConversationBufferMemory:***
- Stores the entire conversation history in a buffer, useful for applications needing full context.

***ConversationBufferWindowMemory:***
- Keeps only a recent window of interactions (e.g., last 5 messages), allowing for focused context while reducing memory usage.

***ConversationTokenBufferMemory:***
- Similar to buffer memory but limits history based on the number of tokens, optimizing memory for token-based models.

***ConversationSummaryMemory:***
- Summarizes past interactions into a concise format, retaining key points instead of full transcripts, ideal for long conversations.

## 2. Chains
Chains are sequences of actions or components used to process inputs and produce structured outputs. They link different modules like language models, prompts, memory, and logic together, enabling complex workflows.

### Types of Chains:
- **Simple Chains:**    Single input → Single output (e.g., Question Answering).
- **Sequential Chains:**    Multi-step operations where each output serves as the next input.
- **Router Chains:**    Routes input to different chains based on user intent.
- **Transform Chains:**    Modify outputs in-between steps.

## 3.  Evaluation
Evaluation refers to the process of assessing the performance and accuracy of language model responses. It helps determine how well the chains, models, and workflows perform in real-world scenarios.

### Types of Evaluation:
- **Human Evaluation:**     Direct feedback from users.
- **Automated Metrics:**     Using predefined benchmarks like BLEU, ROUGE, or F1-scores.
- **Comparative Evaluation:**     Comparing outputs from multiple models or configurations.

## 4. Messages
These are message types used to structure conversations in a clear and contextually organized manner.

- **HumanMessage:**   Represents input from the user (e.g., a question or command).
- **AIMessage:**   Response generated by the AI model, such as ChatGPT’s replies.
- **SystemMessage:**   Provides instructions or sets context for the AI model (e.g., "You are a helpful assistant").

## 5. Example Selectors
- **LengthBasedExampleSelector:**   Selects examples based on their length, suitable for contexts needing either brief or detailed responses.

- **SemanticSimilarityExampleSelector:**   Chooses examples that are semantically similar to a given input, ensuring relevance to user queries.

- **MaximizingRelevanceExampleSelector:**   Focuses on selecting the most relevant examples for a task, prioritizing contextual appropriateness.

- **RandomExampleSelector:**   Randomly selects examples from a set, providing diverse responses to enhance user engagement.